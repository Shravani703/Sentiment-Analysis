{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XraaiIxdBM9X"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import string\n",
        "%matplotlib inline\n",
        "\n",
        "# sklearn specific imports\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from gensim.models import Word2Vec\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5L5KWMjGB52D"
      },
      "source": [
        "### Load and Clean Data\n",
        "\n",
        "In this section we upload and clean our data.\n",
        "\n",
        "Uploaded the data. The data consists of ``products.csv`` with the product reviews."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "QrMCzZc9BlRf",
        "outputId": "f64ba05d-15e2-4586-9415-15b258565c07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of reviews: 5000\n",
            "Dataframe Columns Index(['name', 'review', 'rating'], dtype='object')\n",
            "Name: Stop Pacifier Sucking without tears with Thumbuddy To Love's Binky Fairy Puppet and Adorable Book\n",
            "Review: All of my kids have cried non-stop when I tried to ween them off their pacifier, until I found Thumbuddy To Love's Binky Fairy Puppet.  It is an easy way to work with your kids to allow them to understand where their pacifier is going and help them part from it.This is a must buy book, and a great gift for expecting parents!!  You will save them soo many headaches.Thanks for this book!  You all rock!!\n",
            "Rating: 5\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b1071739-dabe-444f-a35e-b85cf45d3e55\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>review</th>\n",
              "      <th>rating</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
              "      <td>All of my kids have cried nonstop when I tried...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
              "      <td>We wanted to get something to keep track of ou...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
              "      <td>I only purchased a secondyear calendar for my ...</td>\n",
              "      <td>2</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
              "      <td>My daughter had her 1st baby over a year ago S...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Lamaze Peekaboo, I Love You</td>\n",
              "      <td>One of babys first and favorite books and it i...</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b1071739-dabe-444f-a35e-b85cf45d3e55')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b1071739-dabe-444f-a35e-b85cf45d3e55 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b1071739-dabe-444f-a35e-b85cf45d3e55');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                name  \\\n",
              "0  Stop Pacifier Sucking without tears with Thumb...   \n",
              "1    Nature's Lullabies Second Year Sticker Calendar   \n",
              "2    Nature's Lullabies Second Year Sticker Calendar   \n",
              "3    Nature's Lullabies Second Year Sticker Calendar   \n",
              "4                        Lamaze Peekaboo, I Love You   \n",
              "\n",
              "                                              review  rating  sentiment  \n",
              "0  All of my kids have cried nonstop when I tried...       5          1  \n",
              "1  We wanted to get something to keep track of ou...       5          1  \n",
              "2  I only purchased a secondyear calendar for my ...       2         -1  \n",
              "3  My daughter had her 1st baby over a year ago S...       5          1  \n",
              "4  One of babys first and favorite books and it i...       4          1  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "products = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/products.csv')\n",
        "products = products.iloc[0:5000] # For the sake of computation, we will only look at 5000 reviews\n",
        "print('Number of reviews:', len(products))\n",
        "print('Dataframe Columns', products.columns)\n",
        "# Let's look at a specific product\n",
        "print('Name:', products.iloc[0]['name'])\n",
        "print('Review:', products.iloc[0]['review'])\n",
        "print('Rating:', products.iloc[0]['rating'])\n",
        "\n",
        "# REMOVE products with review equal to 3\n",
        "products = products[products['rating'] != 3]\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    if type(text) != str:\n",
        "        return ''\n",
        "    return text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "products['review'] = products['review'].apply(remove_punctuation)\n",
        "len(products)\n",
        "products['sentiment'] = products['rating'].apply(lambda rating : +1 if rating > 3 else -1)\n",
        "products.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZBgOHWRLhTC",
        "outputId": "4f681640-98e8-45df-82e8-9b14dd9f1b1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1maVTHA6-LS"
      },
      "source": [
        "Performed a train/test split.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZjFaReqb69PH"
      },
      "outputs": [],
      "source": [
        "products_train, products_test = train_test_split(products, test_size = 0.2, random_state = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCIsieDzPdbh"
      },
      "source": [
        "### A majority classifier\n",
        "\n",
        "A reasonable first classifier is to figure out what the majority sentiment is in the training set and use that as a predictor on the test set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LS9iTN2sQgk6",
        "outputId": "633179a7-5bdf-4677-b447-175e64e173b1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.586"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# find the majority class (positive or negative) in the training set\n",
        "\n",
        "products_train['sentiment'].value_counts()\n",
        "# 2309 negative reviews and 1691 positive reviews\n",
        "train_sentiment = products_train['sentiment'].mean()\n",
        "products_test.head()\n",
        "\n",
        "# Checking accuracy\n",
        "y_true = products_test['sentiment']\n",
        "y_pred = -1 * np.ones(shape=(len(products_test),1)) #Predicted sentiment is all negative (-1)\n",
        "\n",
        "accuracy_score(y_true, y_pred)\n",
        "\n",
        "#Accuracy is 58.6% when we blindly predict that every review in the test set is of negative sentiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IAQ6ft6RAJ-"
      },
      "source": [
        "### Featurizing sentences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pUfC3He5Lmg"
      },
      "source": [
        "Now we will use a ``CountVectorizer`` to turn our reviews, which our sentences, into features.\n",
        "\n",
        "The count vectorizer takes each sentence, removes punctuation and does a bit of other preprocessing. It then converts the sentence into a list of tokens (words). Then, for each word that appears in the sentence it counts the number of times a given word appears and encodes it in a vector.\n",
        "\n",
        "The CountVectorizer collects a list of all words that appear, ['It', 'is', 'and', 'cat', 'ball']. Then for each sentence it returns a list of how many times each word appears. Thus s1:[1, 1, 0, 1, 0], s2:[1, 1, 1, 1, 1], s3:[1, 1, 2, 2, 1]\n",
        "\n",
        "These vectors are going to form our features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "It4D_H3i5K5o",
        "outputId": "aa6d8a58-671e-421f-b318-a596ce4c3810"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['0' '001' '01' ... 'zoo' 'zookeepers' 'zoos']\n",
            "vocab in count_vectorizer: 14802 dimension of X 14802\n"
          ]
        }
      ],
      "source": [
        "count_vectorizer = CountVectorizer(lowercase=True, token_pattern=u\"(?u)\\\\b\\\\w+\\\\b\", stop_words='english')\n",
        "X_train = count_vectorizer.fit_transform(products_train['review'])\n",
        "y_train = products_train['sentiment']\n",
        "\n",
        "words = count_vectorizer.get_feature_names_out()\n",
        "print(words)\n",
        "\n",
        "# The two numbers printed out should match\n",
        "print('vocab in count_vectorizer:', len(count_vectorizer.get_feature_names_out()), 'dimension of X', X_train.shape[1])\n",
        "\n",
        "# We \"trained\" our count-vectorizer on the train set, now we run it on the test-set\n",
        "X_test = count_vectorizer.transform(products_test['review'])\n",
        "y_test = products_test['sentiment']\n",
        "\n",
        "# Finally we build a tokenizer\n",
        "tokenizer = count_vectorizer.build_analyzer() # We will use this later to tokenize our sentences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkfOFjI1YU1t"
      },
      "source": [
        "The CountVectorizer is fitted onto the training dataset only. The frequencies of the words are learned here, and then they are applied to the test set to estimate the performance of the algorithm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnJTBPT8It5l"
      },
      "source": [
        "### Build a Logistic Regression Classifier on Bag of Words Features\n",
        "\n",
        "Now we build a logistic classifier on our resulting feature representation. The logistic regression classifier is effectively going to learn a feature per word in our list of words on the training set from above.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2iQF2fB47jUQ"
      },
      "outputs": [],
      "source": [
        "#Train a logisitic regression model on the training set\n",
        "sentiment_model = LogisticRegression(C=1).fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1mEbmW18z1i"
      },
      "source": [
        "Now we can use this model to make predictions. Use the model to find the predicted probabilities on a small subset of 3 points"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXyqdzbL84Ve",
        "outputId": "1317db7c-6996-4f6a-8252-e391ebfe40c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[9.87183651e-01 1.28163488e-02]\n",
            " [9.65456091e-01 3.45439088e-02]\n",
            " [1.97189486e-01 8.02810514e-01]\n",
            " [6.19836617e-04 9.99380163e-01]\n",
            " [6.88248772e-01 3.11751228e-01]\n",
            " [9.84068040e-01 1.59319596e-02]\n",
            " [9.44270372e-01 5.57296280e-02]\n",
            " [9.84759031e-01 1.52409692e-02]\n",
            " [1.59305465e-01 8.40694535e-01]\n",
            " [1.33366270e-03 9.98666337e-01]]\n"
          ]
        }
      ],
      "source": [
        "sample_test_data = X_test[1:11]\n",
        "probs = sentiment_model.predict_proba(sample_test_data)\n",
        "print(probs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7n4eeispLG5",
        "outputId": "2eec8188-000d-4e0f-dab3-7a11a4a909a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('bathsi', -0.01879155131918723), ('baththe', 0.08114320284308224), ('bathtime', 0.09278254596438429), ('bathtimeand', -9.306374813260803e-05), ('bathtub', 0.4713882990122745), ('bathtubs', 0.20648651945610857), ('bathtubthe', -0.012675606301970671), ('bathtubthis', 0.05923402067021712), ('batiste', -0.04019695452466787), ('batted', 0.04047100300667036), ('battered', 0.015435312115969279), ('batteries', -0.7777566448284221), ('batteries3', -0.0007042062391138165), ('batteriesnow', -0.00835076210828282), ('battery', -0.672336811637484), ('batterytake', -9.641504853212602e-06), ('batting', -0.012246095625858069), ('battle', -0.01637143240296546), ('bauer', -0.3547659435743857), ('baught', -0.05601071173644782)]\n"
          ]
        }
      ],
      "source": [
        "print(list(zip(words[1500:1520],sentiment_model.coef_[0,1500:1520])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x74WCpBkm2lT"
      },
      "source": [
        "Now we extract the weights from the logistic model and print the words with the five largest and five smallest coefficients."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRGs01nQm28Y",
        "outputId": "37a952b9-1a58-4e30-9ad2-90152db95e06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['0' '001' '01' ... 'zoo' 'zookeepers' 'zoos']\n",
            "['001' '0'], ['001' '0'], ['0' '001'], ['0' '001'], ['001' '0'], "
          ]
        }
      ],
      "source": [
        "# get 5 largest indices\n",
        "best_5 = np.argsort(probs, axis=1)[:,-5:]\n",
        "words = count_vectorizer.get_feature_names_out()\n",
        "print(words)\n",
        "for i in range(5):\n",
        "    print(words[best_5[i]], end=\", \")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlVDjudaI2p9"
      },
      "source": [
        "### Assessing the Bag of words model\n",
        "\n",
        "We will now use the model to build a confusion matrix. A common tool that helps assess classification models is the confusion matrix.\n",
        "\n",
        "We've created a function that will plot a confusion matrix for you given a set of inputs which are the values that should appear within each cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s51wvFKPSn7X"
      },
      "outputs": [],
      "source": [
        "def plot_confusion_matrix(tp, fp, fn, tn):\n",
        "    \"\"\"\n",
        "    Plots a confusion matrix using the values\n",
        "       tp - True Positive\n",
        "       fp - False Positive\n",
        "       fn - False Negative\n",
        "       tn - True Negative\n",
        "    \"\"\"\n",
        "    data = np.matrix([[tp, fp], [fn, tn]])\n",
        "\n",
        "    sns.heatmap(data, annot=True, cmap='YlGnBu',\n",
        "                xticklabels=['Actual Pos.', 'Actual Neg.'],\n",
        "                yticklabels=['Pred. Pos.', 'Pred. Neg.'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8492CwFSpBx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "e29b8edb-c988-479d-c3cf-801e6ebb2ab5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[497  89]\n",
            " [ 92 322]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "tp = 0\n",
        "fp = 0\n",
        "tn = 0\n",
        "fn = 0\n",
        "i= 0\n",
        "pred = sentiment_model.predict(X_test)\n",
        "# TODO: Compute the number of true positives, false positives, true negatives, false negatives\n",
        "# on the test set.\n",
        "from sklearn.metrics import confusion_matrix\n",
        "conf_mat = confusion_matrix(y_test, pred)\n",
        "print(conf_mat)\n",
        "tp = conf_mat[1, 1]\n",
        "fp = conf_mat[0, 1]\n",
        "tn = conf_mat[0, 0]\n",
        "fn = conf_mat[1, 0]\n",
        "plot_confusion_matrix(tp=tp, fp=fp, tn=tn, fn=fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtFk_vRd9wFh"
      },
      "source": [
        "\n",
        "Now that we have succesfully trained a model, let's compare the accuracy of the `sentiment_model` to that of the baseline majority class classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mrhW-tBLxIu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b24dc9f-21d9-4340-b922-ec0e6837c940"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "0.819\n"
          ]
        }
      ],
      "source": [
        "# use sklearns accuracy_score function to compute the accuracy of the model on the test set\n",
        "s1 = accuracy_score(products_test['sentiment'], products_test['sentiment'])\n",
        "s2 = accuracy_score(y_test, pred)\n",
        "print(s1)\n",
        "print(s2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akfXBOStI6dJ"
      },
      "source": [
        "### Build a Classifier using word2vec features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3SPfk5n_I51q"
      },
      "outputs": [],
      "source": [
        "import gensim.downloader as api\n",
        "model = api.load(\"glove-twitter-100\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUby_VyK-OtL"
      },
      "source": [
        "Now we will take each sentence and build a feature vector base on our Word2Vec model.\n",
        "\n",
        "For each sentence in the dataset, we will first split it into words (tokenize it) using the ``count_vectorizer.build_tokenizer()`` function. Then for each word, we will use word2vec to get a word embedding, and we will average these over the words in a review"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPTwlpVtYbJ9"
      },
      "outputs": [],
      "source": [
        "# word2vec model\n",
        "def get_average_word2vec(sentence, tokenizer, word2vec):\n",
        "    tokens = tokenizer(sentence)\n",
        "    v  =0\n",
        "    total = 0\n",
        "    for word in tokens:\n",
        "        if word in word2vec.vocab:\n",
        "            total += 1\n",
        "            vec = word2vec.word_vec(word) # TODO: get the word_vec from the word2vec model as in Problem 4\n",
        "            v += vec/np.linalg.norm(vec)\n",
        "    if total>0:\n",
        "        return v/total\n",
        "    return np.zeros(300)\n",
        "\n",
        "# The tokenizer we use was trained above\n",
        "X_train = np.array([get_average_word2vec(sentence, tokenizer, model) for sentence in products_train['review']])\n",
        "X_test = np.array([get_average_word2vec(sentence, tokenizer, model) for sentence in products_test['review']])\n",
        "\n",
        "# Train a logistic model\n",
        "sentiment_model_w2v = LogisticRegression()\n",
        "model = sentiment_model_w2v.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHURNj92EG8i"
      },
      "source": [
        "Now we can train the model and assess it's accuracy on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ClN78yx714hs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a7749aa-e699-44ab-db4a-52c6019af4c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.757\n"
          ]
        }
      ],
      "source": [
        "# use sklearns accuracy_score function to compute the accuracy of the model on the test set\n",
        "pred1 = sentiment_model_w2v.predict(X_test)\n",
        "model_acc = accuracy_score(y_test, pred1)\n",
        "print(model_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYbS7i4-Mhf4"
      },
      "source": [
        "\n",
        "\n",
        "**The Bag of Words model performs better.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCiJuQnmEKsS"
      },
      "source": [
        "## Hyperparameter tuning\n",
        "\n",
        "Hyperparameter tuning to pick the best possible value of lambda.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "hyper_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
        "sentiment_model_w2v = LogisticRegression()\n",
        "grid_search = GridSearchCV(sentiment_model_w2v, hyper_grid, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "print(\"hyperparameters:\", grid_search.best_params_)\n",
        "print(\"accuracy:\", grid_search.best_score_)\n",
        "\n",
        "# Ans - accuracy 78.7%"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N20n7nL3P_j9",
        "outputId": "cc045164-2681-47c8-dece-f2b918f2fe87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hyperparameters: {'C': 10}\n",
            "accuracy: 0.787\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTfyayPsv3gN"
      },
      "source": [
        "## Bonus 2\n",
        "\n",
        "Remark: There are many ways of taking sentences and featurizing them. Finding new effective ways of doing this is a hot topic of research and in the last few years after word2vec was introduced, several new models such as Glove, Bert, Elmo have been proposed (and buiilt at UW!). These models use Recurrent neural networks, and transformer architectures.\n",
        "\n",
        "Use one of these models - or build your own based on an RNN and try to beat the logistic classifier above.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bv6qPutRww2E"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}